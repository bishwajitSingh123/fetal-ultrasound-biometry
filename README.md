# ğŸ”¬ Fetal Ultrasound Biometry â€” Landmark Detection & Segmentation

**Author:** Bishwajit Prasad Singh  
**Date:** January 2026  
**Domain:** Medical Image Analysis Â· Deep Learning Â· Computer Vision

---

## ğŸ“Œ Project Overview

This project tackles two core tasks in fetal ultrasound biometry using deep learning:

| Task | Goal | Dataset |
|------|------|---------|
| **Task 1 â€” Landmark Detection** | Detect BPD & OFD landmarks (4 keypoints per image) | 622 ultrasound images |
| **Task 2 â€” Segmentation** | Segment fetal structures from ultrasound scans | 622 ultrasound images |

A **hypothesis-driven approach** was used â€” multiple model architectures and training strategies were tested systematically, and the best-performing configuration was selected based on validation metrics.

---

## ğŸ–¼ï¸ Visual Results

### Project Overview
![Project Overview](assets/project-overview.png)

### Task 1 â€” Landmark Detection
![Landmark Detection Demo](assets/demos/landmark-detection-demo.png)

### Task 2 â€” Segmentation
![Segmentation Demo](assets/demos/segmentation-demo.png)

### Training & Performance Comparison
![Training Curves Comparison](assets/results/training-comparison.png)

![Hypothesis Performance Comparison](assets/results/performance-comparison.png)

![Landmark Error Distribution](assets/results/landmark-error-distribution.png)

![Landmark Training Curves](assets/results/landmark-training-curves.png)

---

## ğŸ“ Repository Structure

```
fetal-ultrasound-biometry/
â”‚
â”œâ”€â”€ assets/                          # Portfolio & showcase images
â”‚   â”œâ”€â”€ project-overview.png
â”‚   â”œâ”€â”€ demos/                       # Demo visualizations
â”‚   â””â”€â”€ results/                     # Training & comparison plots
â”‚
â”œâ”€â”€ task_1_landmark/                 # Landmark Detection
â”‚   â”œâ”€â”€ README.md                    # Task-specific documentation
â”‚   â”œâ”€â”€ Python Script/               # Source code
â”‚   â”‚   â”œâ”€â”€ Trainer1.py              # Hypothesis 1 & 2 training
â”‚   â”‚   â”œâ”€â”€ Tester1.py               # Hypothesis 1 & 2 testing
â”‚   â”‚   â”œâ”€â”€ Trainer_Hypothesis3.py   # Hypothesis 3 training
â”‚   â”‚   â””â”€â”€ Testing_Hypothesis3.py   # Hypothesis 3 testing
â”‚   â””â”€â”€ Report/                      # Task 1 report
â”‚
â”œâ”€â”€ task_2_segmentation/             # Segmentation
â”‚   â”œâ”€â”€ README.md                    # Task-specific documentation
â”‚   â”œâ”€â”€ Python Script/               # Source code
â”‚   â”‚   â”œâ”€â”€ Trainer.py               # Segmentation training
â”‚   â”‚   â”œâ”€â”€ Tester.py                # Segmentation testing
â”‚   â”‚   â””â”€â”€ Assets/
â”‚   â”‚       â””â”€â”€ utils.py             # Shared utilities
â”‚   â””â”€â”€ Report/                      # Task 2 reports & PDF
â”‚       â”œâ”€â”€ FINAL_SUMMARY_REPORT.txt
â”‚       â”œâ”€â”€ hypothesis_2_detailed_report.txt
â”‚       â””â”€â”€ Report.pdf
â”‚
â”œâ”€â”€ models/                          # Trained model weights
â”‚   â”œâ”€â”€ landmark/                    # 4 landmark model checkpoints
â”‚   â””â”€â”€ segmentation/                # 8 segmentation model checkpoints
â”‚
â”œâ”€â”€ outputs/                         # All generated visualizations
â”‚   â”œâ”€â”€ landmark_results/            # 12 landmark output images
â”‚   â””â”€â”€ segmentation_results/        # Segmentation output images & logs
â”‚
â”œâ”€â”€ reports/                         # Project-wide documentation
â”‚   â””â”€â”€ landmark_and_segmentation_reports/
â”‚       â””â”€â”€ ReadMe_Complete.txt      # Complete project documentation
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                       # Git ignore rules
â””â”€â”€ README.md                        # This file
```

---

## ğŸ§ª Hypothesis-Based Approach

Both tasks were solved using a structured experimental methodology:

**Task 1 â€” Landmark Detection (BPD & OFD)**
- **Hypothesis 1:** Baseline CNN architecture for 4-landmark detection
- **Hypothesis 2:** Fixed/improved variant with training adjustments
- **Hypothesis 3:** ResNet-based encoder architecture

**Task 2 â€” Segmentation**
- **Hypothesis 1:** First segmentation architecture
- **Hypothesis 2:** Refined architecture (detailed report available)
- **Hypothesis 3:** Third experimental variant
- **Final:** Best configuration selected from all hypotheses

Each hypothesis produced its own trained model, training curves, and evaluation results â€” all stored in `models/` and `outputs/`.

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/YourUsername/fetal-ultrasound-biometry.git
cd fetal-ultrasound-biometry
```

### 2. Create Virtual Environment
```bash
python -m venv venv
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run Landmark Detection
```bash
cd task_1_landmark\Python Script
python Trainer1.py          # Train Hypothesis 1 & 2
python Tester1.py           # Test Hypothesis 1 & 2
python Trainer_Hypothesis3.py    # Train Hypothesis 3
python Testing_Hypothesis3.py   # Test Hypothesis 3
```

### 5. Run Segmentation
```bash
cd task_2_segmentation\Python Script
python Trainer.py           # Train segmentation models
python Tester.py            # Test & evaluate
```

---

## ğŸ“Š Reports & Documentation

| Document | Location | Description |
|----------|----------|-------------|
| Complete Project Doc | `reports/landmark_and_segmentation_reports/ReadMe_Complete.txt` | Full project documentation |
| Segmentation Summary | `task_2_segmentation/Report/FINAL_SUMMARY_REPORT.txt` | Segmentation final results |
| Hypothesis 2 Detail | `task_2_segmentation/Report/hypothesis_2_detailed_report.txt` | Detailed H2 analysis |
| Segmentation Report PDF | `task_2_segmentation/Report/Report.pdf` | Formatted report |

---

## ğŸ› ï¸ Tech Stack

- **PyTorch** â€” Deep learning framework
- **Torchvision** â€” Model architectures & data transforms
- **OpenCV / Pillow** â€” Image loading & processing
- **NumPy / Pandas** â€” Data handling
- **Matplotlib / Seaborn** â€” Visualization
- **Scikit-learn** â€” Metrics & evaluation

---

## ğŸ“ Notes

- All model weights are stored in `models/` â€” these are `.pth` PyTorch checkpoint files
- Full experimental outputs (training curves, prediction visualizations, error analysis) are in `outputs/`
- Portfolio-ready images are pre-selected in `assets/`

---

*Built as part of a structured medical image analysis project â€” January 2026*
